import Foundation

#if canImport(FoundationNetworking)
    import FoundationNetworking
#endif

/// An OpenAI-compatible HTTP API client for Ollama.
///
/// This client provides compatibility with the OpenAI Chat Completions API,
/// allowing you to use existing OpenAI-based code with Ollama locally.
///
/// The OpenAI compatibility layer is available at `http://localhost:11434/v1/`
/// and supports the following endpoints:
/// - `/v1/chat/completions` - Chat completions (compatible with OpenAI)
/// - `/v1/completions` - Text completions (compatible with OpenAI)
///
/// - SeeAlso: [Ollama OpenAI Compatibility Documentation](https://github.com/ollama/ollama/blob/main/docs/openai.md)
@MainActor
public final class OpenAICompatibleClient: Sendable {
    /// The default host URL for the Ollama OpenAI-compatible API.
    public static let defaultHost = URL(string: "http://localhost:11434/v1")!

    /// A default client instance using the default host.
    public static let `default` = OpenAICompatibleClient(host: defaultHost)

    /// The host URL for requests made by the client.
    public let host: URL

    /// The value for the `User-Agent` header sent in requests, if any.
    public let userAgent: String?

    /// The underlying client session.
    private let session: URLSession

    /// Creates a client with the specified session, host, and user agent.
    ///
    /// - Parameters:
    ///   - session: The underlying client session. Defaults to `URLSession(configuration: .default)`.
    ///   - host: The host URL to use for requests. Defaults to `http://localhost:11434/v1`.
    ///   - userAgent: The value for the `User-Agent` header sent in requests, if any. Defaults to `nil`.
    public init(
        session: URLSession = URLSession(configuration: .default),
        host: URL = defaultHost,
        userAgent: String? = nil
    ) {
        var host = host
        if !host.path.hasSuffix("/") {
            host = host.appendingPathComponent("")
        }

        self.host = host
        self.userAgent = userAgent
        self.session = session
    }
}

// MARK: - Chat Completions

extension OpenAICompatibleClient {
    /// Represents a chat completion request in OpenAI format.
    public struct ChatCompletionRequest: Encodable, Sendable {
        /// The model to use for generation.
        public let model: String
        /// The messages of the chat.
        public let messages: [Chat.Message]
        /// Optional format specification.
        public let format: Value?
        /// Additional model parameters.
        public let options: [String: Value]?
        /// Whether to stream the response.
        public var stream: Bool?
        /// Controls how long the model stays loaded.
        public let keepAlive: KeepAlive?

        private enum CodingKeys: String, CodingKey {
            case model
            case messages
            case format
            case options
            case stream
            case keepAlive = "keep_alive"
        }

        public init(
            model: String,
            messages: [Chat.Message],
            format: Value? = nil,
            options: [String: Value]? = nil,
            stream: Bool? = nil,
            keepAlive: KeepAlive? = nil
        ) {
            self.model = model
            self.messages = messages
            self.format = format
            self.options = options
            self.stream = stream
            self.keepAlive = keepAlive
        }

        public func encode(to encoder: Encoder) throws {
            var container = encoder.container(keyedBy: CodingKeys.self)
            try container.encode(model, forKey: .model)
            try container.encode(messages, forKey: .messages)
            try container.encodeIfPresent(format, forKey: .format)
            try container.encodeIfPresent(options, forKey: .options)
            try container.encodeIfPresent(stream, forKey: .stream)

            if let keepAliveValue = keepAlive?.value {
                try container.encode(keepAliveValue, forKey: .keepAlive)
            }
        }
    }

    /// Represents a chat completion response in OpenAI format.
    public struct ChatCompletionResponse: Codable, Sendable {
        /// The unique identifier for the completion.
        public let id: String
        /// The object type, always "chat.completion".
        public let object: String
        /// The Unix timestamp when the completion was created.
        public let created: Int64
        /// The model used for the completion.
        public let model: String
        /// The completion choices.
        public let choices: [Choice]
        /// Usage statistics for the completion.
        public let usage: Usage?

        public struct Choice: Codable, Sendable {
            /// The index of this choice.
            public let index: Int
            /// The message generated by the model.
            public let message: Chat.Message
            /// The reason the completion finished.
            public let finishReason: String?

            private enum CodingKeys: String, CodingKey {
                case index
                case message
                case finishReason = "finish_reason"
            }

            public init(index: Int, message: Chat.Message, finishReason: String? = nil) {
                self.index = index
                self.message = message
                self.finishReason = finishReason
            }
        }

        public struct Usage: Codable, Sendable {
            /// Number of tokens in the prompt.
            public let promptTokens: Int
            /// Number of tokens in the completion.
            public let completionTokens: Int
            /// Total number of tokens used.
            public let totalTokens: Int

            private enum CodingKeys: String, CodingKey {
                case promptTokens = "prompt_tokens"
                case completionTokens = "completion_tokens"
                case totalTokens = "total_tokens"
            }

            public init(promptTokens: Int, completionTokens: Int, totalTokens: Int) {
                self.promptTokens = promptTokens
                self.completionTokens = completionTokens
                self.totalTokens = totalTokens
            }
        }

        public init(
            id: String,
            object: String,
            created: Int64,
            model: String,
            choices: [Choice],
            usage: Usage? = nil
        ) {
            self.id = id
            self.object = object
            self.created = created
            self.model = model
            self.choices = choices
            self.usage = usage
        }
    }

    /// Creates a chat completion using the OpenAI-compatible endpoint.
    ///
    /// - Parameter request: The chat completion request.
    /// - Returns: A `ChatCompletionResponse` containing the completion.
    /// - Throws: An error if the request fails, the response cannot be decoded, or if streaming is requested (use `createChatCompletionStream` instead).
    public func createChatCompletion(
        _ request: ChatCompletionRequest
    ) async throws -> ChatCompletionResponse {
        // Validate that streaming is not requested for this non-streaming method
        if request.stream == true {
            throw Client.Error.requestError(
                "Streaming is not supported by this method. Use createChatCompletionStream() instead."
            )
        }

        let url = host.appendingPathComponent("chat/completions")
        var urlRequest = URLRequest(url: url)
        urlRequest.httpMethod = "POST"
        urlRequest.addValue("application/json", forHTTPHeaderField: "Content-Type")
        urlRequest.addValue("application/json", forHTTPHeaderField: "Accept")

        if let userAgent {
            urlRequest.addValue(userAgent, forHTTPHeaderField: "User-Agent")
        }

        let encoder = JSONEncoder()
        urlRequest.httpBody = try encoder.encode(request)

        let (data, response) = try await session.data(for: urlRequest)
        guard let httpResponse = response as? HTTPURLResponse else {
            throw Client.Error.unexpectedError("Response is not HTTPURLResponse")
        }

        guard (200..<300).contains(httpResponse.statusCode) else {
            if let errorString = String(data: data, encoding: .utf8) {
                throw Client.Error.responseError(response: httpResponse, detail: errorString)
            }
            throw Client.Error.responseError(response: httpResponse, detail: "Unknown error")
        }

        let decoder = JSONDecoder()
        decoder.dateDecodingStrategy = .iso8601WithFractionalSeconds

        return try decoder.decode(ChatCompletionResponse.self, from: data)
    }

    /// Creates a streaming chat completion using the OpenAI-compatible endpoint.
    ///
    /// - Parameter request: The chat completion request (stream parameter is automatically set to true).
    /// - Returns: An async throwing stream of `ChatCompletionResponse` objects containing completion chunks.
    /// - Throws: An error if the request fails or responses cannot be decoded.
    public func createChatCompletionStream(
        _ request: ChatCompletionRequest
    ) -> AsyncThrowingStream<ChatCompletionResponse, Swift.Error> {
        AsyncThrowingStream { continuation in
            let task = Task {
                let decoder = JSONDecoder()
                decoder.dateDecodingStrategy = .iso8601WithFractionalSeconds

                do {
                    // Create a new request with streaming enabled
                    var streamRequest = request
                    streamRequest.stream = true

                    let url = host.appendingPathComponent("chat/completions")
                    var urlRequest = URLRequest(url: url)
                    urlRequest.httpMethod = "POST"
                    urlRequest.addValue("application/json", forHTTPHeaderField: "Content-Type")
                    urlRequest.addValue("application/json", forHTTPHeaderField: "Accept")

                    if let userAgent {
                        urlRequest.addValue(userAgent, forHTTPHeaderField: "User-Agent")
                    }

                    let encoder = JSONEncoder()
                    urlRequest.httpBody = try encoder.encode(streamRequest)

                    let (bytes, response) = try await session.bytes(for: urlRequest)
                    guard let httpResponse = response as? HTTPURLResponse else {
                        throw Client.Error.unexpectedError("Response is not HTTPURLResponse")
                    }

                    guard (200..<300).contains(httpResponse.statusCode) else {
                        var errorData = Data()
                        for try await byte in bytes {
                            errorData.append(byte)
                        }
                        if let errorString = String(data: errorData, encoding: .utf8) {
                            throw Client.Error.responseError(response: httpResponse, detail: errorString)
                        }
                        throw Client.Error.responseError(response: httpResponse, detail: "Unknown error")
                    }

                    var buffer = Data()

                    for try await byte in bytes {
                        buffer.append(byte)

                        // Look for newline to separate JSON objects
                        while let newlineIndex = buffer.firstIndex(of: UInt8(ascii: "\n")) {
                            let chunk = buffer[..<newlineIndex]
                            buffer = buffer[buffer.index(after: newlineIndex)...]

                            if !chunk.isEmpty {
                                // Skip "data: " prefix if present (SSE format)
                                var jsonData = chunk
                                if let dataPrefix = "data: ".data(using: .utf8),
                                   chunk.starts(with: dataPrefix) {
                                    jsonData = chunk.dropFirst(dataPrefix.count)
                                }

                                // Skip [DONE] message
                                if let doneMessage = "[DONE]".data(using: .utf8),
                                   jsonData.starts(with: doneMessage) {
                                    continue
                                }

                                let decoded = try decoder.decode(ChatCompletionResponse.self, from: jsonData)
                                continuation.yield(decoded)
                            }
                        }
                    }

                    continuation.finish()
                } catch {
                    continuation.finish(throwing: error)
                }
            }

            continuation.onTermination = { _ in
                task.cancel()
            }
        }
    }
}

// MARK: - Completions

extension OpenAICompatibleClient {
    /// Represents a text completion request in OpenAI format.
    public struct CompletionRequest: Codable, Sendable {
        /// The model to use for generation.
        public let model: String
        /// The prompt to generate from.
        public let prompt: String
        /// The suffix that comes after the completion.
        public let suffix: String?
        /// Maximum number of tokens to generate.
        public let maxTokens: Int?
        /// Temperature for sampling.
        public let temperature: Double?
        /// Whether to stream the response.
        public var stream: Bool?

        private enum CodingKeys: String, CodingKey {
            case model
            case prompt
            case suffix
            case maxTokens = "max_tokens"
            case temperature
            case stream
        }

        public init(
            model: String,
            prompt: String,
            suffix: String? = nil,
            maxTokens: Int? = nil,
            temperature: Double? = nil,
            stream: Bool? = nil
        ) {
            self.model = model
            self.prompt = prompt
            self.suffix = suffix
            self.maxTokens = maxTokens
            self.temperature = temperature
            self.stream = stream
        }
    }

    /// Represents a text completion response in OpenAI format.
    public struct CompletionResponse: Codable, Sendable {
        /// The unique identifier for the completion.
        public let id: String
        /// The object type, always "text_completion".
        public let object: String
        /// The Unix timestamp when the completion was created.
        public let created: Int64
        /// The model used for the completion.
        public let model: String
        /// The completion choices.
        public let choices: [Choice]

        public struct Choice: Codable, Sendable {
            /// The index of this choice.
            public let index: Int
            /// The generated text.
            public let text: String
            /// The reason the completion finished.
            public let finishReason: String?

            private enum CodingKeys: String, CodingKey {
                case index
                case text
                case finishReason = "finish_reason"
            }

            public init(index: Int, text: String, finishReason: String? = nil) {
                self.index = index
                self.text = text
                self.finishReason = finishReason
            }
        }

        public init(
            id: String,
            object: String,
            created: Int64,
            model: String,
            choices: [Choice]
        ) {
            self.id = id
            self.object = object
            self.created = created
            self.model = model
            self.choices = choices
        }
    }

    /// Creates a text completion using the OpenAI-compatible endpoint.
    ///
    /// - Parameter request: The completion request.
    /// - Returns: A `CompletionResponse` containing the completion.
    /// - Throws: An error if the request fails, the response cannot be decoded, or if streaming is requested (use `createCompletionStream` instead).
    public func createCompletion(
        _ request: CompletionRequest
    ) async throws -> CompletionResponse {
        // Validate that streaming is not requested for this non-streaming method
        if request.stream == true {
            throw Client.Error.requestError(
                "Streaming is not supported by this method. Use createCompletionStream() instead."
            )
        }

        let url = host.appendingPathComponent("completions")
        var urlRequest = URLRequest(url: url)
        urlRequest.httpMethod = "POST"
        urlRequest.addValue("application/json", forHTTPHeaderField: "Content-Type")
        urlRequest.addValue("application/json", forHTTPHeaderField: "Accept")

        if let userAgent {
            urlRequest.addValue(userAgent, forHTTPHeaderField: "User-Agent")
        }

        let encoder = JSONEncoder()
        urlRequest.httpBody = try encoder.encode(request)

        let (data, response) = try await session.data(for: urlRequest)
        guard let httpResponse = response as? HTTPURLResponse else {
            throw Client.Error.unexpectedError("Response is not HTTPURLResponse")
        }

        guard (200..<300).contains(httpResponse.statusCode) else {
            if let errorString = String(data: data, encoding: .utf8) {
                throw Client.Error.responseError(response: httpResponse, detail: errorString)
            }
            throw Client.Error.responseError(response: httpResponse, detail: "Unknown error")
        }

        let decoder = JSONDecoder()
        decoder.dateDecodingStrategy = .iso8601WithFractionalSeconds

        return try decoder.decode(CompletionResponse.self, from: data)
    }

    /// Creates a streaming text completion using the OpenAI-compatible endpoint.
    ///
    /// - Parameter request: The completion request (stream parameter is automatically set to true).
    /// - Returns: An async throwing stream of `CompletionResponse` objects containing completion chunks.
    /// - Throws: An error if the request fails or responses cannot be decoded.
    public func createCompletionStream(
        _ request: CompletionRequest
    ) -> AsyncThrowingStream<CompletionResponse, Swift.Error> {
        AsyncThrowingStream { continuation in
            let task = Task {
                let decoder = JSONDecoder()
                decoder.dateDecodingStrategy = .iso8601WithFractionalSeconds

                do {
                    // Create a new request with streaming enabled
                    var streamRequest = request
                    streamRequest.stream = true

                    let url = host.appendingPathComponent("completions")
                    var urlRequest = URLRequest(url: url)
                    urlRequest.httpMethod = "POST"
                    urlRequest.addValue("application/json", forHTTPHeaderField: "Content-Type")
                    urlRequest.addValue("application/json", forHTTPHeaderField: "Accept")

                    if let userAgent {
                        urlRequest.addValue(userAgent, forHTTPHeaderField: "User-Agent")
                    }

                    let encoder = JSONEncoder()
                    urlRequest.httpBody = try encoder.encode(streamRequest)

                    let (bytes, response) = try await session.bytes(for: urlRequest)
                    guard let httpResponse = response as? HTTPURLResponse else {
                        throw Client.Error.unexpectedError("Response is not HTTPURLResponse")
                    }

                    guard (200..<300).contains(httpResponse.statusCode) else {
                        var errorData = Data()
                        for try await byte in bytes {
                            errorData.append(byte)
                        }
                        if let errorString = String(data: errorData, encoding: .utf8) {
                            throw Client.Error.responseError(response: httpResponse, detail: errorString)
                        }
                        throw Client.Error.responseError(response: httpResponse, detail: "Unknown error")
                    }

                    var buffer = Data()

                    for try await byte in bytes {
                        buffer.append(byte)

                        // Look for newline to separate JSON objects
                        while let newlineIndex = buffer.firstIndex(of: UInt8(ascii: "\n")) {
                            let chunk = buffer[..<newlineIndex]
                            buffer = buffer[buffer.index(after: newlineIndex)...]

                            if !chunk.isEmpty {
                                // Skip "data: " prefix if present (SSE format)
                                var jsonData = chunk
                                if let dataPrefix = "data: ".data(using: .utf8),
                                   chunk.starts(with: dataPrefix) {
                                    jsonData = chunk.dropFirst(dataPrefix.count)
                                }

                                // Skip [DONE] message
                                if let doneMessage = "[DONE]".data(using: .utf8),
                                   jsonData.starts(with: doneMessage) {
                                    continue
                                }

                                let decoded = try decoder.decode(CompletionResponse.self, from: jsonData)
                                continuation.yield(decoded)
                            }
                        }
                    }

                    continuation.finish()
                } catch {
                    continuation.finish(throwing: error)
                }
            }

            continuation.onTermination = { _ in
                task.cancel()
            }
        }
    }
}
